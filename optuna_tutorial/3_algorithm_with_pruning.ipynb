{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Optimization Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna는 HyperParameter sampling을 위한 SOTA algorithm을 채택하고 효율적이지 못한 trials를 pruning할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna는 다음의 Algorithm을 제공한다.\n",
    "\n",
    "- Tree-structured Parzen Estimator algorithm implemented in :class:`optuna.samplers.TPESampler`\n",
    "\n",
    "- CMA-ES based algorithm implemented in :class:`optuna.samplers.CmaEsSampler`\n",
    "\n",
    "- Grid Search implemented in :class:`optuna.samplers.GridSampler`\n",
    "\n",
    "- Random Search implemented in :class:`optuna.samplers.RandomSampler`\n",
    "\n",
    "The default sampler is :class:`optuna.samplers.TPESampler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 14:59:22,851]\u001b[0m A new study created in memory with name: no-name-8d4f3d7c-2387-4ae6-9c66-183c7afe7482\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler is TPESampler\n"
     ]
    }
   ],
   "source": [
    "# Default Sampler는 TPESampler\n",
    "study = optuna.create_study()\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 14:59:52,884]\u001b[0m A new study created in memory with name: no-name-80a9c90c-dcfc-427b-ba18-5f79cf6509a5\u001b[0m\n",
      "\u001b[32m[I 2021-11-26 14:59:52,888]\u001b[0m A new study created in memory with name: no-name-9b5cadff-60d2-4f70-9073-8f3a491bec6d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler is RandomSampler\n",
      "Sampler is CmaEsSampler\n"
     ]
    }
   ],
   "source": [
    "# 다른 Sampler를 활용하고 싶을 경우, sampler 옵션 활용\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Pruners``가 안좋은 trials에 대해서는 훈련의 앞쪽에서 자동으로 멈추게 만든다. (a.k.a automated early-stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna는 다음의 Prunig Algorithm을 제공한다.\n",
    "\n",
    "- Asynchronous Successive Halving algorithm implemented in :class:`optuna.pruners.SuccessiveHalvingPruner`\n",
    "\n",
    "- Hyperband algorithm implemented in :class:`optuna.pruners.HyperbandPruner`\n",
    "\n",
    "- Median pruning algorithm implemented in :class:`optuna.pruners.MedianPruner`\n",
    "\n",
    "- Threshold pruning algorithm implemented in :class:`optuna.pruners.ThresholdPruner`\n",
    "\n",
    "We use :class:`optuna.pruners.MedianPruner` in most examples. 성능 역시 다른 pruning algorithm보다 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activating Pruners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pruning을 하기 위해서 학습 중에 각 step에서 report와 should_prune을 호출 해야한다.\n",
    "- ``optuna.trial.Trial.report``: 중간 objective 값을 모니터링한다.\n",
    "- ``optuna.trial.Trial.should_prune``: 미리 정의된 조건을 충족하지 않으면 trial을 종료한다.\n",
    "\n",
    "We would recommend using integration modules for major machine learning frameworks. [Github-Optuna](https://github.com/optuna/optuna-examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris() # iris data laod\n",
    "    classes = list(set(iris.target))\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(\n",
    "        iris.data, iris.target, test_size = 0.25, random_state = 0\n",
    "    )\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-1, log=True)\n",
    "    clf = sklearn.linear_model.SGDClassifier(alpha=alpha)\n",
    "\n",
    "    for step in range(100) :\n",
    "        clf.partial_fit(train_x, train_y, classes=classes)\n",
    "        \n",
    "        # Report intermediate objective value\n",
    "        intermediate_value = 1.0 - clf.score(valid_x, valid_y)\n",
    "        trial.report(intermediate_value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return 1.0 - clf.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:18,578]\u001b[0m A new study created in memory with name: no-name-146afbe2-c7ea-41c7-9db9-195daddec8dc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: no-name-146afbe2-c7ea-41c7-9db9-195daddec8dc\n",
      "A new study created in memory with name: no-name-146afbe2-c7ea-41c7-9db9-195daddec8dc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:18,853]\u001b[0m Trial 0 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.00563340118988228}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.00563340118988228}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 0 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.00563340118988228}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,087]\u001b[0m Trial 1 finished with value: 0.368421052631579 and parameters: {'alpha': 0.00014237215428023828}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.368421052631579 and parameters: {'alpha': 0.00014237215428023828}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 1 finished with value: 0.368421052631579 and parameters: {'alpha': 0.00014237215428023828}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,289]\u001b[0m Trial 2 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.03436152303760004}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.03436152303760004}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 2 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.03436152303760004}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,495]\u001b[0m Trial 3 finished with value: 0.3421052631578947 and parameters: {'alpha': 0.0007697499193719187}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.3421052631578947 and parameters: {'alpha': 0.0007697499193719187}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 3 finished with value: 0.3421052631578947 and parameters: {'alpha': 0.0007697499193719187}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,873]\u001b[0m Trial 4 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.0005660252695084958}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.0005660252695084958}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 4 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.0005660252695084958}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,891]\u001b[0m Trial 5 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 pruned. \n",
      "Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:19,969]\u001b[0m Trial 6 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. \n",
      "Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,181]\u001b[0m Trial 7 finished with value: 0.21052631578947367 and parameters: {'alpha': 0.0037281882173837875}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 0.21052631578947367 and parameters: {'alpha': 0.0037281882173837875}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 7 finished with value: 0.21052631578947367 and parameters: {'alpha': 0.0037281882173837875}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,231]\u001b[0m Trial 8 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,252]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,265]\u001b[0m Trial 10 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 pruned. \n",
      "Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,278]\u001b[0m Trial 11 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,297]\u001b[0m Trial 12 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 pruned. \n",
      "Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,326]\u001b[0m Trial 13 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 pruned. \n",
      "Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,371]\u001b[0m Trial 14 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 pruned. \n",
      "Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,383]\u001b[0m Trial 15 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 pruned. \n",
      "Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,399]\u001b[0m Trial 16 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 pruned. \n",
      "Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,414]\u001b[0m Trial 17 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 pruned. \n",
      "Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,430]\u001b[0m Trial 18 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-26 15:19:20,682]\u001b[0m Trial 19 finished with value: 0.26315789473684215 and parameters: {'alpha': 0.0016820260534773238}. Best is trial 0 with value: 0.052631578947368474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 finished with value: 0.26315789473684215 and parameters: {'alpha': 0.0016820260534773238}. Best is trial 0 with value: 0.052631578947368474.\n",
      "Trial 19 finished with value: 0.26315789473684215 and parameters: {'alpha': 0.0016820260534773238}. Best is trial 0 with value: 0.052631578947368474.\n"
     ]
    }
   ],
   "source": [
    "# Add stream handler of stdout to show the messages\n",
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Sampler and Pruner Should be Used?\n",
    "\n",
    "- `optuna.samplers.RandomSampler` with `optuna.pruners.MedianPruner` is the best.\n",
    "- `optuna.samplers.TPESampler` with `optuna.pruners.Hyperband` is the best.\n",
    "\n",
    "However, note that the benchmark is not deep learning.  \n",
    "\n",
    "For deep learning tasks,consult the below table.  \n",
    "This table is from the `Ozaki et al., Hyperparameter Optimization Methods: Overview and Characteristics, in IEICE Trans, Vol.J103-D No.9 pp.615-631, 2020 <https://doi.org/10.14923/transinfj.2019JDR0003>`_ paper,\n",
    "which is written in Japanese.\n",
    "\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n",
    "| Parallel Compute Resource | Categorical/Conditional Hyperparameters | Recommended Algorithms                                        |\n",
    "+===========================+=========================================+===============================================================+\n",
    "| Limited                   | No                                      | TPE. GP-EI if search space is low-dimensional and continuous. |\n",
    "+                           +-----------------------------------------+---------------------------------------------------------------+\n",
    "|                           | Yes                                     | TPE. GP-EI if search space is low-dimensional and continuous  |\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n",
    "| Sufficient                | No                                      | CMA-ES, Random Search                                         |\n",
    "+                           +-----------------------------------------+---------------------------------------------------------------+\n",
    "|                           | Yes                                     | Random Search or Genetic Algorithm                            |\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Modules for Pruning\n",
    "Optuna는 ``integraion`` module을 제공하는 데, 이를 활용하여 puning을 간단하게 실행할 수 있다.\n",
    "\n",
    "다음 처럼 활용할 수 있다.\n",
    "-> visualization.ipynb에서 확인하자.\n",
    "\n",
    "```python\n",
    "pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-error')\n",
    "bst = xgb.train(param, dtrain, evals=[(dvalid, 'validation')], callbacks=[pruning_callback])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "337f1a600d345c50cd007a2461b073851b5ec4b77bc6c65adb33d085b42175ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
