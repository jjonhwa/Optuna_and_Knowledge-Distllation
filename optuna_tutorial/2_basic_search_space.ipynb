{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 핵심\n",
    "- Search할 Parameter가 증가할수록 필요한 시간이 exponentially하게 증가한다.\n",
    "- 중요한 Parameter에 대해서만 Search하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonic Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음과 같은 방법으로 Search Space를 정하여 탐색을 진행할 수 있다.\n",
    "def objective(trial):\n",
    "    # Categorical parameter\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"MomentumSGD\", \"Adam\"])\n",
    "\n",
    "    # Integer parameter\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "\n",
    "    # Integer parameter (log)\n",
    "    num_channels = trial.suggest_int(\"num_channels\", 32, 512, log=True)\n",
    "\n",
    "    # Integer parameter (discretized)\n",
    "    num_units = trial.suggest_int(\"num_units\", 10, 100, step=5)\n",
    "\n",
    "    # Floating point parameter\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 1.0)\n",
    "\n",
    "    # Floating point parameter (log)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Floating point parameter (discretized)\n",
    "    drop_path_rate = trial.suggest_float(\"drop_path_rate\", 0.0, 1.0, step=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Parameter Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if문을 활용하여 Conditional하게 search space를 지정할 수 있다.\n",
    "# 이를 branches를 활용한 방법이라 한다.\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "\n",
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['SVC', 'RandomForest']) # SVC와 RandomForest 중 택1\n",
    "\n",
    "    if classifier_name == 'SVC': # SVC일 경우 if문에서의 parameter 중 선택\n",
    "        svc_c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True) # 1e-10 ~ 1e10 중 선택\n",
    "        classifier_obj = sklearn.svm.SVC(C=svc_c)\n",
    "    else:\n",
    "        rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32, log=True)\n",
    "        classifier_obj = sklearn.ensemble.RandomForestClassifier(max_deptn=rf_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def creat_model(trial, in_size):\n",
    "    '''\n",
    "    for loop를 활용해서 각 layer마다 다른 parameter를 활용할 수 있다.\n",
    "    '''\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "\n",
    "    layers = []\n",
    "    for i in range(n_layers) :\n",
    "        n_units = trial.suggest_int('n_units_{}'.format(i), 4, 128, log=True)\n",
    "        layers.append(nn.Linear(in_size, n_units))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_size = n_units\n",
    "    layers.append(nn.Linear(in_size, 10))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "337f1a600d345c50cd007a2461b073851b5ec4b77bc6c65adb33d085b42175ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
